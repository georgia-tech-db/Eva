{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import os\n",
    "import keras\n",
    "import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "from time import time\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from keras import callbacks\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Input\n",
    "from keras.initializers import VarianceScaling\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jbang36/eva/data/ua_detrac/small-data/MVI_20011'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()\n",
    "home_dir = os.path.abspath('../')\n",
    "home_dir\n",
    "data_dir = os.path.join(home_dir, 'data', 'ua_detrac', 'small-data', 'MVI_20011')\n",
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-536966b9b348>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg_table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mimage_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_images_nn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownsize_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrayscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-536966b9b348>\u001b[0m in \u001b[0;36mload_images_nn\u001b[0;34m(image_dir, downsize_rate, grayscale)\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0mimg_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_height\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdownsize_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_width\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdownsize_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m       \u001b[0mimg_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_height\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdownsize_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_width\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdownsize_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "def load_images_nn(image_dir, downsize_rate = 1, grayscale = False):\n",
    "    \"\"\"\n",
    "    Loading images in a non normalized form\n",
    "    :param image_dir:\n",
    "    :param downsize_rate:\n",
    "    :param grayscale:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    image_height = 540\n",
    "    image_width = 960\n",
    "    image_channels = 3\n",
    "    file_names = []\n",
    "    for root, subdirs, files in os.walk(image_dir):\n",
    "      files.sort()\n",
    "      for file in files:\n",
    "        file_names.append(os.path.join(root, file))\n",
    "\n",
    "    if grayscale == False:\n",
    "      img_table = np.ndarray(shape=(len(file_names), image_height / downsize_rate, image_width / downsize_rate, image_channels))\n",
    "    else:\n",
    "      img_table = np.ndarray(shape=(len(file_names), image_height / downsize_rate, image_width / downsize_rate, 1))\n",
    "\n",
    "    for i in xrange(len(file_names)):\n",
    "      file_name = file_names[i]\n",
    "      if grayscale:\n",
    "        img = cv2.imread(file_name,0)\n",
    "      else:\n",
    "        img = cv2.imread(file_name, 1)\n",
    "\n",
    "      img = cv2.resize(img, (image_width / downsize_rate, image_height / downsize_rate))\n",
    "      img_table[i] = img[:,:, np.newaxis]\n",
    "\n",
    "    return img_table\n",
    "\n",
    "image_table = load_images_nn(data_dir, downsize_rate = 12, grayscale = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the training and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "n_samples = image_table.shape[0]\n",
    "train_x, test_x, train_y, test_y = train_test_split(image_table, [], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "image_index = random.randint(0,100) # You may select anything up to 60,000\n",
    "plt.imshow(train_x[image_index], cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, width, height, channels = image_table.shape\n",
    "train_x = train_x.reshape(-1, width*height*channels).astype('float32')\n",
    "test_x = test_x.reshape(-1, width*height*channels).astype('float32')\n",
    "\n",
    "# TODO: Must perform normalization for the autoencoder to perform well??\n",
    "train_x /= 255.0\n",
    "test_x /= 255.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will first train the autoencoder network + k means to train the DEC network\n",
    "# We will see if the DEC network can improve upon the predictions made / compare and contrast by\n",
    "# Selecting 3 frames from each group\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(width*height*channels,))\n",
    "\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(500, activation='relu')(input_img)\n",
    "encoded = Dense(500, activation='relu')(encoded)\n",
    "encoded = Dense(2000, activation='relu')(encoded)\n",
    "encoded = Dense(10, activation='sigmoid')(encoded)\n",
    "\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(2000, activation='relu')(encoded)\n",
    "decoded = Dense(500, activation='relu')(decoded)\n",
    "decoded = Dense(500, activation='relu')(decoded)\n",
    "decoded = Dense(width*height*channels)(decoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Model(input_img, encoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "start_time = time.time()\n",
    "train_history = autoencoder.fit(train_x, train_x, epochs=500, batch_size=2048, validation_data=(test_x, test_x))\n",
    "print(\"Total time it took to train autoencoder is \", time.time() - start_time, \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DEC Implementation\n",
    "\n",
    "\n",
    "Keras implementation for Deep Embedded Clustering (DEC) algorithm:\n",
    "\n",
    "\n",
    "Original Author:\n",
    "    Xifeng Guo. 2017.1.30\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def autoencoder(dims, act='relu', init='glorot_uniform'):\n",
    "    \"\"\"\n",
    "    Fully connected auto-encoder model, symmetric.\n",
    "    Arguments:\n",
    "        dims: list of number of units in each layer of encoder. dims[0] is input dim, dims[-1] is units in hidden layer.\n",
    "            The decoder is symmetric with encoder. So number of layers of the auto-encoder is 2*len(dims)-1\n",
    "        act: activation, not applied to Input, Hidden and Output layers\n",
    "    return:\n",
    "        (ae_model, encoder_model), Model of autoencoder and model of encoder\n",
    "    \"\"\"\n",
    "    n_stacks = len(dims) - 1\n",
    "    # input\n",
    "    x = Input(shape=(dims[0],), name='input')\n",
    "    h = x\n",
    "\n",
    "    # internal layers in encoder\n",
    "    for i in range(n_stacks-1):\n",
    "        h = Dense(dims[i + 1], activation=act, kernel_initializer=init, name='encoder_%d' % i)(h)\n",
    "\n",
    "    # hidden layer\n",
    "    h = Dense(dims[-1], kernel_initializer=init, name='encoder_%d' % (n_stacks - 1))(h)  # hidden layer, features are extracted from here\n",
    "\n",
    "    y = h\n",
    "    # internal layers in decoder\n",
    "    for i in range(n_stacks-1, 0, -1):\n",
    "        y = Dense(dims[i], activation=act, kernel_initializer=init, name='decoder_%d' % i)(y)\n",
    "\n",
    "    # output\n",
    "    y = Dense(dims[0], kernel_initializer=init, name='decoder_0')(y)\n",
    "\n",
    "    return Model(inputs=x, outputs=y, name='AE'), Model(inputs=x, outputs=h, name='encoder')\n",
    "\n",
    "\n",
    "class ClusteringLayer(Layer):\n",
    "    \"\"\"\n",
    "    Clustering layer converts input sample (feature) to soft label, i.e. a vector that represents the probability of the\n",
    "    sample belonging to each cluster. The probability is calculated with student's t-distribution.\n",
    "\n",
    "    # Example\n",
    "    ```\n",
    "        model.add(ClusteringLayer(n_clusters=10))\n",
    "    ```\n",
    "    # Arguments\n",
    "        n_clusters: number of clusters.\n",
    "        weights: list of Numpy array with shape `(n_clusters, n_features)` witch represents the initial cluster centers.\n",
    "        alpha: parameter in Student's t-distribution. Default to 1.0.\n",
    "    # Input shape\n",
    "        2D tensor with shape: `(n_samples, n_features)`.\n",
    "    # Output shape\n",
    "        2D tensor with shape: `(n_samples, n_clusters)`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_clusters, weights=None, alpha=1.0, **kwargs):\n",
    "        if 'input_shape' not in kwargs and 'input_dim' in kwargs:\n",
    "            kwargs['input_shape'] = (kwargs.pop('input_dim'),)\n",
    "        super(ClusteringLayer, self).__init__(**kwargs)\n",
    "        self.n_clusters = n_clusters\n",
    "        self.alpha = alpha\n",
    "        self.initial_weights = weights\n",
    "        self.input_spec = InputSpec(ndim=2)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 2\n",
    "        input_dim = input_shape[1]\n",
    "        self.input_spec = InputSpec(dtype=K.floatx(), shape=(None, input_dim))\n",
    "        self.clusters = self.add_weight((self.n_clusters, input_dim), initializer='glorot_uniform', name='clusters')\n",
    "        if self.initial_weights is not None:\n",
    "            self.set_weights(self.initial_weights)\n",
    "            del self.initial_weights\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        \"\"\" student t-distribution, as same as used in t-SNE algorithm.\n",
    "                 q_ij = 1/(1+dist(x_i, u_j)^2), then normalize it.\n",
    "        Arguments:\n",
    "            inputs: the variable containing data, shape=(n_samples, n_features)\n",
    "        Return:\n",
    "            q: student's t-distribution, or soft labels for each sample. shape=(n_samples, n_clusters)\n",
    "        \"\"\"\n",
    "        q = 1.0 / (1.0 + (K.sum(K.square(K.expand_dims(inputs, axis=1) - self.clusters), axis=2) / self.alpha))\n",
    "        q **= (self.alpha + 1.0) / 2.0\n",
    "        q = K.transpose(K.transpose(q) / K.sum(q, axis=1))\n",
    "        return q\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        assert input_shape and len(input_shape) == 2\n",
    "        return input_shape[0], self.n_clusters\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'n_clusters': self.n_clusters}\n",
    "        base_config = super(ClusteringLayer, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "class DEC(object):\n",
    "    def __init__(self,\n",
    "                 dims,\n",
    "                 n_clusters=10,\n",
    "                 alpha=1.0,\n",
    "                 init='glorot_uniform'):\n",
    "\n",
    "        super(DEC, self).__init__()\n",
    "\n",
    "        self.dims = dims\n",
    "        self.input_dim = dims[0]\n",
    "        self.n_stacks = len(self.dims) - 1\n",
    "\n",
    "        self.n_clusters = n_clusters\n",
    "        self.alpha = alpha\n",
    "        self.autoencoder, self.encoder = autoencoder(self.dims, init=init)\n",
    "\n",
    "        # prepare DEC model\n",
    "        clustering_layer = ClusteringLayer(self.n_clusters, name='clustering')(self.encoder.output)\n",
    "        self.model = Model(inputs=self.encoder.input, outputs=clustering_layer)\n",
    "\n",
    "    def pretrain(self, x, y=None, optimizer='adam', epochs=200, batch_size=256, save_dir='results/temp'):\n",
    "        print('...Pretraining...')\n",
    "        self.autoencoder.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "        csv_logger = callbacks.CSVLogger(save_dir + '/pretrain_log.csv')\n",
    "        cb = [csv_logger]\n",
    "        if y is not None:\n",
    "            class PrintACC(callbacks.Callback):\n",
    "                def __init__(self, x, y):\n",
    "                    self.x = x\n",
    "                    self.y = y\n",
    "                    super(PrintACC, self).__init__()\n",
    "\n",
    "                def on_epoch_end(self, epoch, logs=None):\n",
    "                    if epoch % int(epochs/10) != 0:\n",
    "                        return\n",
    "                    feature_model = Model(self.model.input,\n",
    "                                          self.model.get_layer(\n",
    "                                              'encoder_%d' % (int(len(self.model.layers) / 2) - 1)).output)\n",
    "                    features = feature_model.predict(self.x)\n",
    "                    km = KMeans(n_clusters=len(np.unique(self.y)), n_init=20, n_jobs=4)\n",
    "                    y_pred = km.fit_predict(features)\n",
    "                    # print()\n",
    "                    print(' '*8 + '|==>  acc: %.4f,  nmi: %.4f  <==|'\n",
    "                          % (metrics.acc(self.y, y_pred), metrics.nmi(self.y, y_pred)))\n",
    "\n",
    "            cb.append(PrintACC(x, y))\n",
    "\n",
    "        # begin pretraining\n",
    "        t0 = time()\n",
    "        self.autoencoder.fit(x, x, batch_size=batch_size, epochs=epochs, callbacks=cb)\n",
    "        print('Pretraining time: ', time() - t0)\n",
    "        self.autoencoder.save_weights(save_dir + '/ae_weights.h5')\n",
    "        print('Pretrained weights are saved to %s/ae_weights.h5' % save_dir)\n",
    "        self.pretrained = True\n",
    "\n",
    "    def load_weights(self, weights):  # load weights of DEC model\n",
    "        self.model.load_weights(weights)\n",
    "\n",
    "    def extract_features(self, x):\n",
    "        return self.encoder.predict(x)\n",
    "\n",
    "    def predict(self, x):  # predict cluster labels using the output of clustering layer\n",
    "        q = self.model.predict(x, verbose=0)\n",
    "        return q.argmax(1)\n",
    "\n",
    "    @staticmethod\n",
    "    def target_distribution(q):\n",
    "        weight = q ** 2 / q.sum(0)\n",
    "        return (weight.T / weight.sum(1)).T\n",
    "\n",
    "    def compile(self, optimizer='sgd', loss='kld'):\n",
    "        self.model.compile(optimizer=optimizer, loss=loss)\n",
    "\n",
    "    def fit(self, x, y=None, maxiter=2e4, batch_size=256, tol=1e-3,\n",
    "            update_interval=140, save_dir='./results/temp'):\n",
    "\n",
    "        print('Update interval', update_interval)\n",
    "        save_interval = x.shape[0] / batch_size * 5  # 5 epochs\n",
    "        print('Save interval', save_interval)\n",
    "\n",
    "        # Step 1: initialize cluster centers using k-means\n",
    "        t1 = time()\n",
    "        print('Initializing cluster centers with k-means.')\n",
    "        kmeans = KMeans(n_clusters=self.n_clusters, n_init=20)\n",
    "        y_pred = kmeans.fit_predict(self.encoder.predict(x))\n",
    "        y_pred_last = np.copy(y_pred)\n",
    "        self.model.get_layer(name='clustering').set_weights([kmeans.cluster_centers_])\n",
    "\n",
    "        # Step 2: deep clustering\n",
    "        # logging file\n",
    "        import csv\n",
    "        logfile = open(save_dir + '/dec_log.csv', 'w')\n",
    "        logwriter = csv.DictWriter(logfile, fieldnames=['iter', 'acc', 'nmi', 'ari', 'loss'])\n",
    "        logwriter.writeheader()\n",
    "\n",
    "        loss = 0\n",
    "        index = 0\n",
    "        index_array = np.arange(x.shape[0])\n",
    "        for ite in range(int(maxiter)):\n",
    "            if ite % update_interval == 0:\n",
    "                q = self.model.predict(x, verbose=0)\n",
    "                p = self.target_distribution(q)  # update the auxiliary target distribution p\n",
    "\n",
    "                # evaluate the clustering performance\n",
    "                y_pred = q.argmax(1)\n",
    "                if y is not None:\n",
    "                    acc = np.round(metrics.acc(y, y_pred), 5)\n",
    "                    nmi = np.round(metrics.nmi(y, y_pred), 5)\n",
    "                    ari = np.round(metrics.ari(y, y_pred), 5)\n",
    "                    loss = np.round(loss, 5)\n",
    "                    logdict = dict(iter=ite, acc=acc, nmi=nmi, ari=ari, loss=loss)\n",
    "                    logwriter.writerow(logdict)\n",
    "                    print('Iter %d: acc = %.5f, nmi = %.5f, ari = %.5f' % (ite, acc, nmi, ari), ' ; loss=', loss)\n",
    "\n",
    "                # check stop criterion\n",
    "                delta_label = np.sum(y_pred != y_pred_last).astype(np.float32) / y_pred.shape[0]\n",
    "                y_pred_last = np.copy(y_pred)\n",
    "                if ite > 0 and delta_label < tol:\n",
    "                    print('delta_label ', delta_label, '< tol ', tol)\n",
    "                    print('Reached tolerance threshold. Stopping training.')\n",
    "                    logfile.close()\n",
    "                    break\n",
    "\n",
    "            # train on batch\n",
    "            # if index == 0:\n",
    "            #     np.random.shuffle(index_array)\n",
    "            idx = index_array[index * batch_size: min((index+1) * batch_size, x.shape[0])]\n",
    "            self.model.train_on_batch(x=x[idx], y=p[idx])\n",
    "            index = index + 1 if (index + 1) * batch_size <= x.shape[0] else 0\n",
    "\n",
    "            # save intermediate model\n",
    "            if ite % save_interval == 0:\n",
    "                print('saving model to:', save_dir + '/DEC_model_' + str(ite) + '.h5')\n",
    "                self.model.save_weights(save_dir + '/DEC_model_' + str(ite) + '.h5')\n",
    "\n",
    "            ite += 1\n",
    "\n",
    "        # save the trained model\n",
    "        logfile.close()\n",
    "        print('saving model to:', save_dir + '/DEC_model_final.h5')\n",
    "        self.model.save_weights(save_dir + '/DEC_model_final.h5')\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Pretraining...\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "failed initializing StreamExecutor for CUDA device ordinal 0: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_OUT_OF_MEMORY: out of memory; total memory reported: 12788498432",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-843334b646b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m dec.pretrain(x=train_x, y=train_y, optimizer=pretrain_optimizer,\n\u001b[1;32m     25\u001b[0m              \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpretrain_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m              save_dir=save_dir)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-ee42afeb121c>\u001b[0m in \u001b[0;36mpretrain\u001b[0;34m(self, x, y, optimizer, epochs, batch_size, save_dir)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;31m# begin pretraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Pretraining time: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/ae_weights.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/pp36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/miniconda2/envs/pp36/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/pp36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2696\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2697\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_make_callable_from_options'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2698\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2699\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/pp36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    184\u001b[0m                 config = tf.ConfigProto(intra_op_parallelism_threads=num_thread,\n\u001b[1;32m    185\u001b[0m                                         allow_soft_placement=True)\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0m_SESSION\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_SESSION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/pp36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, target, graph, config)\u001b[0m\n\u001b[1;32m   1549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \"\"\"\n\u001b[0;32m-> 1551\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m     \u001b[0;31m# NOTE(mrry): Create these on first `__enter__` to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_graph_context_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/pp36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, target, graph, config)\u001b[0m\n\u001b[1;32m    674\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_NewSessionRef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m       \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: failed initializing StreamExecutor for CUDA device ordinal 0: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_OUT_OF_MEMORY: out of memory; total memory reported: 12788498432"
     ]
    }
   ],
   "source": [
    "# setting the hyper parameters\n",
    "init = 'glorot_uniform'\n",
    "pretrain_optimizer = 'adam'\n",
    "dataset = 'mnist'\n",
    "batch_size = 2048\n",
    "maxiter = 2e4\n",
    "tol = 0.001\n",
    "save_dir = 'results'\n",
    "\n",
    "import os\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "update_interval = 200\n",
    "pretrain_epochs = 500\n",
    "init = VarianceScaling(scale=1. / 3., mode='fan_in',\n",
    "                       distribution='uniform')  # [-limit, limit], limit=sqrt(1./fan_in)\n",
    "#pretrain_optimizer = SGD(lr=1, momentum=0.9)\n",
    "\n",
    "\n",
    "# prepare the DEC model\n",
    "dec = DEC(dims=[train_x.shape[-1], 500, 500, 2000, 10], n_clusters=10, init=init)\n",
    "\n",
    "dec.pretrain(x=train_x, y=train_y, optimizer=pretrain_optimizer,\n",
    "             epochs=pretrain_epochs, batch_size=batch_size,\n",
    "             save_dir=save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After pretraining, we will apply the clustering onto the uadetrac dataset\n",
    "# What we expect are groupings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pp36",
   "language": "python",
   "name": "pp36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

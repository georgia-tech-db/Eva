{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import os\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "import time\n",
    "\n",
    "from keras import callbacks\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Input\n",
    "from keras.initializers import VarianceScaling\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "\n",
    "#from scipy.misc import imread\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score, normalized_mutual_info_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To stop potential randomness\n",
    "seed = 128\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jbang36/eva/others/jupyter\n",
      "/home/jbang36/eva/others\n",
      "/home/jbang36/eva/others/data/mnist\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "root_dir = os.path.abspath('../')\n",
    "data_dir = os.path.join(root_dir, 'data', 'mnist')\n",
    "print(root_dir)\n",
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_x, train_y), (test_x, test_y) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f00d4552240>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADmlJREFUeJzt3X+MVPW5x/HPc7FEsq0GZPkRi3ex2VSNsXSzIUbMDTe9NEJIkD9UiDaYmLtVIbGxJiXU5KL+Q25uW0m8klAlUK1LNUXhD1NRrD9ItLqgFwG1/mBJQYQFCwV/octz/9iD2eqe7wzz68zu834lk505zzlznox+ODPzPXO+5u4CEM+/FN0AgGIQfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQZ3VyJ2NHz/e29raGrlLIJTe3l4dPnzYylm3qvCb2VWSVkoaJekBd1+RWr+trU09PT3V7BJAQmdnZ9nrVvy238xGSfpfSbMlXSJpoZldUunzAWisaj7zT5f0rru/7+4nJa2XNK82bQGot2rCf76kvw16vC9b9k/MrMvMesysp6+vr4rdAailun/b7+6r3b3T3TtbW1vrvTsAZaom/PslTRn0+LvZMgDDQDXhf1VSu5lNNbPRkhZI2lSbtgDUW8VDfe7+pZktkfSUBob61rj7rpp1BqCuqhrnd/cnJT1Zo14ANBCn9wJBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QVEOn6AYGO3nyZLL+1FNPJevPPfdcxfvu7u5O1js6OpL1W2+9NVmfM2fOGffUaBz5gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiCoqsb5zaxX0nFJ/ZK+dPfOWjSF4ePTTz9N1u+6667c2vr165Pb7t27N1mfMGFCsj537tzc2vz585PbbtiwIVl/6KGHkvXhMM5fi5N8/t3dD9fgeQA0EG/7gaCqDb9L2mxm28ysqxYNAWiMat/2X+nu+81sgqSnzewtd39h8ArZPwpdknTBBRdUuTsAtVLVkd/d92d/D0l6XNL0IdZZ7e6d7t7Z2tpaze4A1FDF4TezFjP7zun7kn4saWetGgNQX9W87Z8o6XEzO/08j7j7n2rSFYC6qzj87v6+pB/UsBc0oY0bNybrd955Z7K+c2f+m8GxY8cmt7399tuT9bvvvjtZb2lpSdZTFi9enKyXOk9gOGCoDwiK8ANBEX4gKMIPBEX4gaAIPxAUl+4ObseOHcn6Nddck6yfOnUqWV+5cmVu7eabb05uO3r06GS9lNRPgidNmpTc9uKLL07Wt27dWlFPzYQjPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ExTj/CHf8+PFkfcaMGcm6uyfr27dvT9Yvu+yyZD2lv78/Wb/hhhuS9cceeyy39sQTTyS3TV32W5JGwlWpOPIDQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCM849wK1asSNZPnDiRrHd1padgrGYcv5RSl+YuNcV3ynnnnVfxtiMFR34gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCKrkOL+ZrZE0V9Ihd780WzZO0h8ktUnqlXStu/+9fm0i5ZNPPsmtdXd3V/Xc99xzT1XbHzt2LLd23XXXJbfdvHlzVft+8cUXc2uXX355Vc89EpRz5F8r6aqvLVsqaYu7t0vakj0GMIyUDL+7vyDpo68tnidpXXZ/naSra9wXgDqr9DP/RHc/kN3/UNLEGvUDoEGq/sLPBy7ylnuhNzPrMrMeM+vp6+urdncAaqTS8B80s8mSlP09lLeiu69290537xwJFz0ERopKw79J0qLs/iJJG2vTDoBGKRl+M+uW9JKk75vZPjO7SdIKSbPM7B1J/5E9BjCMlBznd/eFOaUf1bgXVOjUqVO5tc8//7yq5z5y5Eiy3tLSkqwvXrw4t/bMM88ktz377LOT9YcffjhZ7+joyK2ZWXLbCDjDDwiK8ANBEX4gKMIPBEX4gaAIPxAUl+4eAVLDeR9//HFVz/3oo48m6/fee2+yfvTo0dzauHHjktu+/PLLyXp7e3uyjjSO/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOP8I0B/f39ubezYscltU5fWlqTly5dX0tJX5s2bl1t75JFHktuW+kkvqsORHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCYpx/BHjrrbdya6lzAMoxZsyYZP3+++9P1hcsWJBbYxy/WBz5gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiCokuP8ZrZG0lxJh9z90mzZckn/KakvW22Zuz9Zryaj27NnT7I+a9as3NrJkyer2vfs2bOT9dQ4vsRYfjMr58i/VtJVQyz/jbtPy24EHxhmSobf3V+Q9FEDegHQQNV85l9iZjvMbI2Zpa8VBaDpVBr+VZK+J2mapAOSfpW3opl1mVmPmfX09fXlrQagwSoKv7sfdPd+dz8l6beSpifWXe3une7e2draWmmfAGqsovCb2eRBD+dL2lmbdgA0SjlDfd2SZkoab2b7JP2XpJlmNk2SS+qV9NM69gigDkqG390XDrH4wTr0Etbzzz+frKfG8SVp0qRJubU77rgjue3atWuT9Q0bNiTr9913X7Jeav8oDmf4AUERfiAowg8ERfiBoAg/EBThB4Li0t0NsGvXrmS91M9izSxZ37x5c27toosuSm67bdu2ZP21115L1j/77LNkHc2LIz8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBMU4f5m++OKL3Nru3buT23Z0dCTrZ52V/s+wZcuWZL3UWH7KLbfckqx3d3cn62+//XbF+0axOPIDQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCM85fpyJEjubVp06Yltx0zZkyyXmqsfMqUKcl6yokTJ5L12267LVkfNWpUsl7qPAE0L478QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxBUyXF+M5si6XeSJkpySavdfaWZjZP0B0ltknolXevuf69fq/VVajx8zpw5FT/3s88+m6yXGsd392T9lVdeya1df/31yW3fe++9ZH3mzJnJ+hVXXJGso3mVc+T/UtLP3f0SSZdLWmxml0haKmmLu7dL2pI9BjBMlAy/ux9w9+3Z/eOS3pR0vqR5ktZlq62TdHW9mgRQe2f0md/M2iT9UNJfJE109wNZ6UMNfCwAMEyUHX4z+7akP0r6mbv/Y3DNBz6UDvnB1My6zKzHzHr6+vqqahZA7ZQVfjP7lgaC/3t335AtPmhmk7P6ZEmHhtrW3Ve7e6e7d7a2ttaiZwA1UDL8NjBF7IOS3nT3Xw8qbZK0KLu/SNLG2rcHoF7K+UnvDEk/kfSGmb2eLVsmaYWkR83sJkl7JV1bnxYb44MPPkjWS01VnTJ9+vRk/ejRo8n6smXLkvVVq1adcU+n3Xjjjcn6Aw88UPFzo7mVDL+7b5WUN0H8j2rbDoBG4Qw/ICjCDwRF+IGgCD8QFOEHgiL8QFBcujszcWL6pwlTp07Nre3Zsye57YUXXpisHzt2LFkvdR7AhAkTcmtLl6Z/bLlkyZJkvdSluzF8ceQHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAY58+ce+65yfpLL72UW+vq6kpuu2nTpop6Oq29vT1Z7+npya2dc845Ve0bIxdHfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IinH+MqV+779xI/OVYPjhyA8ERfiBoAg/EBThB4Ii/EBQhB8IivADQZUMv5lNMbM/m9luM9tlZrdly5eb2X4zez27zal/uwBqpZyTfL6U9HN3325m35G0zcyezmq/cff/qV97AOqlZPjd/YCkA9n942b2pqTz690YgPo6o8/8ZtYm6YeS/pItWmJmO8xsjZmNzdmmy8x6zKynr6+vqmYB1E7Z4Tezb0v6o6Sfufs/JK2S9D1J0zTwzuBXQ23n7qvdvdPdO1tbW2vQMoBaKCv8ZvYtDQT/9+6+QZLc/aC797v7KUm/lTS9fm0CqLVyvu03SQ9KetPdfz1o+eRBq82XtLP27QGol3K+7Z8h6SeS3jCz17NlyyQtNLNpklxSr6Sf1qVDAHVRzrf9WyXZEKUna98OgEbhDD8gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQ5u6N25lZn6S9gxaNl3S4YQ2cmWbtrVn7kuitUrXs7V/dvazr5TU0/N/YuVmPu3cW1kBCs/bWrH1J9FaponrjbT8QFOEHgio6/KsL3n9Ks/bWrH1J9FapQnor9DM/gOIUfeQHUJBCwm9mV5nZ22b2rpktLaKHPGbWa2ZvZDMP9xTcyxozO2RmOwctG2dmT5vZO9nfIadJK6i3ppi5OTGzdKGvXbPNeN3wt/1mNkrSXyXNkrRP0quSFrr77oY2ksPMeiV1unvhY8Jm9m+STkj6nbtfmi37b0kfufuK7B/Ose7+iybpbbmkE0XP3JxNKDN58MzSkq6WdKMKfO0SfV2rAl63Io780yW96+7vu/tJSeslzSugj6bn7i9I+uhri+dJWpfdX6eB/3kaLqe3puDuB9x9e3b/uKTTM0sX+tol+ipEEeE/X9LfBj3ep+aa8tslbTazbWbWVXQzQ5iYTZsuSR9KmlhkM0MoOXNzI31tZummee0qmfG61vjC75uudPcOSbMlLc7e3jYlH/jM1kzDNWXN3NwoQ8ws/ZUiX7tKZ7yutSLCv1/SlEGPv5stawruvj/7e0jS42q+2YcPnp4kNft7qOB+vtJMMzcPNbO0muC1a6YZr4sI/6uS2s1sqpmNlrRA0qYC+vgGM2vJvoiRmbVI+rGab/bhTZIWZfcXSdpYYC//pFlmbs6bWVoFv3ZNN+O1uzf8JmmOBr7xf0/SL4voIaevCyX9X3bbVXRvkro18DbwCw18N3KTpPMkbZH0jqRnJI1rot4ekvSGpB0aCNrkgnq7UgNv6XdIej27zSn6tUv0Vcjrxhl+QFB84QcERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+IKj/B+4Jb0bYriM/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "image_index = 7777 # You may select anything up to 60,000\n",
    "print(train_y[image_index]) # The label is 8\n",
    "plt.imshow(train_x[image_index], cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x.reshape(-1, 784).astype('float32')\n",
    "test_x = test_x.reshape(-1, 784).astype('float32')\n",
    "train_x /= 255.0\n",
    "test_x /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2000)              1002000   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                20010     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2000)              22000     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 500)               1000500   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 784)               392784    \n",
      "=================================================================\n",
      "Total params: 3,330,794\n",
      "Trainable params: 3,330,794\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Autoencoder network\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(784,))\n",
    "\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(500, activation='relu')(input_img)\n",
    "encoded = Dense(500, activation='relu')(encoded)\n",
    "encoded = Dense(2000, activation='relu')(encoded)\n",
    "\n",
    "#Value I want to play around with is thisi signmoid\n",
    "encoded = Dense(10, activation='sigmoid')(encoded)\n",
    "\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(2000, activation='relu')(encoded)\n",
    "decoded = Dense(500, activation='relu')(decoded)\n",
    "decoded = Dense(500, activation='relu')(decoded)\n",
    "decoded = Dense(784)(decoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.summary()\n",
    "encoder = Model(input_img, encoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.0738 - val_loss: 0.0647\n",
      "Epoch 2/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0639 - val_loss: 0.0635\n",
      "Epoch 3/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0630 - val_loss: 0.0605\n",
      "Epoch 4/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0556 - val_loss: 0.0506\n",
      "Epoch 5/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0467 - val_loss: 0.0424\n",
      "Epoch 6/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0394 - val_loss: 0.0365\n",
      "Epoch 7/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0346 - val_loss: 0.0326\n",
      "Epoch 8/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0315 - val_loss: 0.0295\n",
      "Epoch 9/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0291 - val_loss: 0.0277\n",
      "Epoch 10/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0274 - val_loss: 0.0264\n",
      "Epoch 11/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0259 - val_loss: 0.0249\n",
      "Epoch 12/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0250 - val_loss: 0.0241\n",
      "Epoch 13/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0239 - val_loss: 0.0233\n",
      "Epoch 14/200\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.0231 - val_loss: 0.0225\n",
      "Epoch 15/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0225 - val_loss: 0.0222\n",
      "Epoch 16/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0219 - val_loss: 0.0215\n",
      "Epoch 17/200\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.0216 - val_loss: 0.0213\n",
      "Epoch 18/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0210 - val_loss: 0.0206\n",
      "Epoch 19/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0207 - val_loss: 0.0204\n",
      "Epoch 20/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0202 - val_loss: 0.0200\n",
      "Epoch 21/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0202 - val_loss: 0.0199\n",
      "Epoch 22/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0197 - val_loss: 0.0195\n",
      "Epoch 23/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0196 - val_loss: 0.0195\n",
      "Epoch 24/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0193 - val_loss: 0.0191\n",
      "Epoch 25/200\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.0191 - val_loss: 0.0191\n",
      "Epoch 26/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0188 - val_loss: 0.0187\n",
      "Epoch 27/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0187 - val_loss: 0.0186\n",
      "Epoch 28/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0184 - val_loss: 0.0187\n",
      "Epoch 29/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0183 - val_loss: 0.0184\n",
      "Epoch 30/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0181 - val_loss: 0.0183\n",
      "Epoch 31/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0180 - val_loss: 0.0179\n",
      "Epoch 32/200\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.0179 - val_loss: 0.0179\n",
      "Epoch 33/200\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.0177 - val_loss: 0.0178\n",
      "Epoch 34/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0176 - val_loss: 0.0178\n",
      "Epoch 35/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0174 - val_loss: 0.0176\n",
      "Epoch 36/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0173 - val_loss: 0.0175\n",
      "Epoch 37/200\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.0172 - val_loss: 0.0173\n",
      "Epoch 38/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0171 - val_loss: 0.0173\n",
      "Epoch 39/200\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.0170 - val_loss: 0.0172\n",
      "Epoch 40/200\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.0169 - val_loss: 0.0171\n",
      "Epoch 41/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0168 - val_loss: 0.0170\n",
      "Epoch 42/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0168 - val_loss: 0.0171\n",
      "Epoch 43/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0166 - val_loss: 0.0170\n",
      "Epoch 44/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0165 - val_loss: 0.0167\n",
      "Epoch 45/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0165 - val_loss: 0.0167\n",
      "Epoch 46/200\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.0163 - val_loss: 0.0166\n",
      "Epoch 47/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0163 - val_loss: 0.0166\n",
      "Epoch 48/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0162 - val_loss: 0.0165\n",
      "Epoch 49/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0161 - val_loss: 0.0164\n",
      "Epoch 50/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0160 - val_loss: 0.0165\n",
      "Epoch 51/200\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.0160 - val_loss: 0.0163\n",
      "Epoch 52/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0158 - val_loss: 0.0162\n",
      "Epoch 53/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0158 - val_loss: 0.0161\n",
      "Epoch 54/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0156 - val_loss: 0.0161\n",
      "Epoch 55/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0157 - val_loss: 0.0160\n",
      "Epoch 56/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0156 - val_loss: 0.0163\n",
      "Epoch 57/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0155 - val_loss: 0.0160\n",
      "Epoch 58/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0155 - val_loss: 0.0160\n",
      "Epoch 59/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0154 - val_loss: 0.0158\n",
      "Epoch 60/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0154 - val_loss: 0.0158\n",
      "Epoch 61/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0152 - val_loss: 0.0158\n",
      "Epoch 62/200\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.0153 - val_loss: 0.0158\n",
      "Epoch 63/200\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.0151 - val_loss: 0.0157\n",
      "Epoch 64/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0151 - val_loss: 0.0156\n",
      "Epoch 65/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0150 - val_loss: 0.0157\n",
      "Epoch 66/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0149 - val_loss: 0.0155\n",
      "Epoch 67/200\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.0150 - val_loss: 0.0154\n",
      "Epoch 68/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0149 - val_loss: 0.0154\n",
      "Epoch 69/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0148 - val_loss: 0.0154\n",
      "Epoch 70/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0147 - val_loss: 0.0155\n",
      "Epoch 71/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0147 - val_loss: 0.0153\n",
      "Epoch 72/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0146 - val_loss: 0.0152\n",
      "Epoch 73/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0146 - val_loss: 0.0152\n",
      "Epoch 74/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0145 - val_loss: 0.0153\n",
      "Epoch 75/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0146 - val_loss: 0.0151\n",
      "Epoch 76/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0144 - val_loss: 0.0156\n",
      "Epoch 77/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.0145 - val_loss: 0.0151\n",
      "Epoch 78/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0144 - val_loss: 0.0151\n",
      "Epoch 79/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0143 - val_loss: 0.0150\n",
      "Epoch 80/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0143 - val_loss: 0.0151\n",
      "Epoch 81/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0142 - val_loss: 0.0149\n",
      "Epoch 82/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0143 - val_loss: 0.0149\n",
      "Epoch 83/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0141 - val_loss: 0.0149\n",
      "Epoch 84/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0141 - val_loss: 0.0149\n",
      "Epoch 85/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0140 - val_loss: 0.0149\n",
      "Epoch 86/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0140 - val_loss: 0.0151\n",
      "Epoch 87/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0140 - val_loss: 0.0148\n",
      "Epoch 88/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0139 - val_loss: 0.0147\n",
      "Epoch 89/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0139 - val_loss: 0.0147\n",
      "Epoch 90/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0139 - val_loss: 0.0148\n",
      "Epoch 91/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0139 - val_loss: 0.0147\n",
      "Epoch 92/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0138 - val_loss: 0.0148\n",
      "Epoch 93/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0137 - val_loss: 0.0146\n",
      "Epoch 94/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0137 - val_loss: 0.0148\n",
      "Epoch 95/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0138 - val_loss: 0.0145\n",
      "Epoch 96/200\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.0136 - val_loss: 0.0146\n",
      "Epoch 97/200\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.0137 - val_loss: 0.0148\n",
      "Epoch 98/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0136 - val_loss: 0.0146\n",
      "Epoch 99/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0135 - val_loss: 0.0145\n",
      "Epoch 100/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0135 - val_loss: 0.0145\n",
      "Epoch 101/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0135 - val_loss: 0.0144\n",
      "Epoch 102/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0135 - val_loss: 0.0144\n",
      "Epoch 103/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0134 - val_loss: 0.0144\n",
      "Epoch 104/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0134 - val_loss: 0.0144\n",
      "Epoch 105/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0134 - val_loss: 0.0143\n",
      "Epoch 106/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0134 - val_loss: 0.0144\n",
      "Epoch 107/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0133 - val_loss: 0.0142\n",
      "Epoch 108/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0132 - val_loss: 0.0143\n",
      "Epoch 109/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0132 - val_loss: 0.0142\n",
      "Epoch 110/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0132 - val_loss: 0.0142\n",
      "Epoch 111/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0132 - val_loss: 0.0142\n",
      "Epoch 112/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0132 - val_loss: 0.0142\n",
      "Epoch 113/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0131 - val_loss: 0.0142\n",
      "Epoch 114/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0132 - val_loss: 0.0142\n",
      "Epoch 115/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0131 - val_loss: 0.0141\n",
      "Epoch 116/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0130 - val_loss: 0.0142\n",
      "Epoch 117/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0131 - val_loss: 0.0141\n",
      "Epoch 118/200\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.0129 - val_loss: 0.0141\n",
      "Epoch 119/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0129 - val_loss: 0.0141\n",
      "Epoch 120/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0129 - val_loss: 0.0141\n",
      "Epoch 121/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0129 - val_loss: 0.0141\n",
      "Epoch 122/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0129 - val_loss: 0.0140\n",
      "Epoch 123/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0129 - val_loss: 0.0139\n",
      "Epoch 124/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0128 - val_loss: 0.0140\n",
      "Epoch 125/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0128 - val_loss: 0.0140\n",
      "Epoch 126/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0127 - val_loss: 0.0141\n",
      "Epoch 127/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0128 - val_loss: 0.0140\n",
      "Epoch 128/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0128 - val_loss: 0.0140\n",
      "Epoch 129/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0127 - val_loss: 0.0140\n",
      "Epoch 130/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0127 - val_loss: 0.0139\n",
      "Epoch 131/200\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.0127 - val_loss: 0.0139\n",
      "Epoch 132/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0126 - val_loss: 0.0140\n",
      "Epoch 133/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0126 - val_loss: 0.0139\n",
      "Epoch 134/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0126 - val_loss: 0.0140\n",
      "Epoch 135/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0125 - val_loss: 0.0139\n",
      "Epoch 136/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0125 - val_loss: 0.0138\n",
      "Epoch 137/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0125 - val_loss: 0.0137\n",
      "Epoch 138/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0125 - val_loss: 0.0138\n",
      "Epoch 139/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0125 - val_loss: 0.0138\n",
      "Epoch 140/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0125 - val_loss: 0.0138\n",
      "Epoch 141/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0124 - val_loss: 0.0137\n",
      "Epoch 142/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0124 - val_loss: 0.0137\n",
      "Epoch 143/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0123 - val_loss: 0.0137\n",
      "Epoch 144/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0125 - val_loss: 0.0138\n",
      "Epoch 145/200\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.0123 - val_loss: 0.0137\n",
      "Epoch 146/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0124 - val_loss: 0.0136\n",
      "Epoch 147/200\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.0123 - val_loss: 0.0136\n",
      "Epoch 148/200\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.0124 - val_loss: 0.0137\n",
      "Epoch 149/200\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.0122 - val_loss: 0.0136\n",
      "Epoch 150/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0122 - val_loss: 0.0136\n",
      "Epoch 151/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0122 - val_loss: 0.0136\n",
      "Epoch 152/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0121 - val_loss: 0.0136\n",
      "Epoch 153/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.0123 - val_loss: 0.0137\n",
      "Epoch 154/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0121 - val_loss: 0.0135\n",
      "Epoch 155/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0121 - val_loss: 0.0135\n",
      "Epoch 156/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0121 - val_loss: 0.0137\n",
      "Epoch 157/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0121 - val_loss: 0.0135\n",
      "Epoch 158/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0121 - val_loss: 0.0135\n",
      "Epoch 159/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0121 - val_loss: 0.0135\n",
      "Epoch 160/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0121 - val_loss: 0.0135\n",
      "Epoch 161/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0120 - val_loss: 0.0135\n",
      "Epoch 162/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0120 - val_loss: 0.0136\n",
      "Epoch 163/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0120 - val_loss: 0.0134\n",
      "Epoch 164/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0120 - val_loss: 0.0134\n",
      "Epoch 165/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0120 - val_loss: 0.0135\n",
      "Epoch 166/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0119 - val_loss: 0.0134\n",
      "Epoch 167/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0119 - val_loss: 0.0135\n",
      "Epoch 168/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0119 - val_loss: 0.0134\n",
      "Epoch 169/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0119 - val_loss: 0.0134\n",
      "Epoch 170/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0119 - val_loss: 0.0135\n",
      "Epoch 171/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0119 - val_loss: 0.0133\n",
      "Epoch 172/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0118 - val_loss: 0.0134\n",
      "Epoch 173/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0119 - val_loss: 0.0133\n",
      "Epoch 174/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0118 - val_loss: 0.0133\n",
      "Epoch 175/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0118 - val_loss: 0.0135\n",
      "Epoch 176/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0118 - val_loss: 0.0133\n",
      "Epoch 177/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0118 - val_loss: 0.0134\n",
      "Epoch 178/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0118 - val_loss: 0.0134\n",
      "Epoch 179/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0118 - val_loss: 0.0134\n",
      "Epoch 180/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0117 - val_loss: 0.0134\n",
      "Epoch 181/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0117 - val_loss: 0.0133\n",
      "Epoch 182/200\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.0116 - val_loss: 0.0133\n",
      "Epoch 183/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0117 - val_loss: 0.0134\n",
      "Epoch 184/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0117 - val_loss: 0.0133\n",
      "Epoch 185/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0116 - val_loss: 0.0133\n",
      "Epoch 186/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0117 - val_loss: 0.0133\n",
      "Epoch 187/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0116 - val_loss: 0.0133\n",
      "Epoch 188/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0116 - val_loss: 0.0133\n",
      "Epoch 189/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0116 - val_loss: 0.0133\n",
      "Epoch 190/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0116 - val_loss: 0.0134\n",
      "Epoch 191/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0116 - val_loss: 0.0133\n",
      "Epoch 192/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0116 - val_loss: 0.0133\n",
      "Epoch 193/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0116 - val_loss: 0.0132\n",
      "Epoch 194/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0115 - val_loss: 0.0132\n",
      "Epoch 195/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0116 - val_loss: 0.0133\n",
      "Epoch 196/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0115 - val_loss: 0.0134\n",
      "Epoch 197/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0116 - val_loss: 0.0132\n",
      "Epoch 198/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0114 - val_loss: 0.0131\n",
      "Epoch 199/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0115 - val_loss: 0.0132\n",
      "Epoch 200/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0114 - val_loss: 0.0132\n"
     ]
    }
   ],
   "source": [
    "train_history = autoencoder.fit(train_x, train_x, epochs=200, batch_size=2048, validation_data=(test_x, test_x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_auto_train = encoder.predict(train_x)\n",
    "pred_auto = encoder.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.80977505 0.12959942 0.3405935  0.6722396  0.41602293 0.71425617\n",
      " 0.813507   0.6283709  0.14332438 0.22720961]\n",
      "[0.17451365 0.3762826  0.52468884 0.74122053 0.45649487 0.6522731\n",
      " 0.58688444 0.4142691  0.6644179  0.49010903]\n",
      "4.62 µs ± 666 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "print(pred_auto_train[0])\n",
    "print(pred_auto_train[1])\n",
    "%timeit np.linalg.norm(pred_auto_train[0] - pred_auto_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 1 9 2 1 3 1 4 3 5 3 6 1 7 2 8 6 9 4 0 9 1 1 2 4 3 2 7 3 8 6 9 0 5 6\n",
      " 0 7 6 1 8 7 9 3 9 8 5 9 3 3 0 7 4 9 8 0 9 4 1 4 4 6 0 4 5 6 1 0 0 1 7 1 6\n",
      " 3 0 2 1 1 7 9 0 2 6 7 8 3 9 0 4 6 7 4 6 8 0 7 8 3 1]\n"
     ]
    }
   ],
   "source": [
    "# Compute the L2 distance matrix\n",
    "\n",
    "print(train_y[:100])\n",
    "\n",
    "n_train = len(pred_auto_train)\n",
    "n_train = 1000\n",
    "dist_m = np.ndarray(shape = (n_train, n_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_train):\n",
    "    for j in range(n_train):\n",
    "        if j <= i:\n",
    "            # Make dist with itself and repeating distances irrelevant\n",
    "            dist_m[i][j] = -1\n",
    "        else:\n",
    "            dist_m[i][j] = np.linalg.norm(pred_auto_train[i] - pred_auto_train[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_flattened = np.reshape(dist_m, (1, -1))\n",
    "dist_done = dist_flattened[dist_flattened != -1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "buckets = np.linspace(0,1000,10000)\n",
    "buckets_count = np.zeros(10000)\n",
    "\n",
    "points_not_categorized = 0\n",
    "for i in range(len(dist_flattened)):\n",
    "    if dist_flattened[i] != -1:\n",
    "        # we have granularity of 0.1 \n",
    "        index_conversion = int(dist_flattened * 10)\n",
    "        if index_conversion > len(buckets_count): \n",
    "            points_not_categorized += 1\n",
    "        else:    \n",
    "            buckets_count[index_conversion] += 1\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 0., 0., ..., 0., 0., 1.]),\n",
       " array([0.04013323, 0.04030069, 0.04046814, ..., 1.71435685, 1.7145243 ,\n",
       "        1.71469176]),\n",
       " <a list of 10000 Patch objects>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/jbang36/anaconda3/envs/jb_py35/lib/python3.5/site-packages/matplotlib/figure.py:2369: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  warnings.warn(\"This figure includes Axes that are not compatible \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# draw the buckets as a histogram\n",
    "import matplotlib.pyplot as plt\n",
    "fig, axs = plt.subplots(1, 1, sharey=True, tight_layout=True)\n",
    "axs.hist(dist_done, bins=10000)\n",
    "plt.xlabel(\"Distance\")\n",
    "plt.ylabel(\"Number of datapoints\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the above graph is not meaningful, I want to see there is any difference in terms of L2 distance\n",
    "# for points that are within a category and those that are not\n",
    "\n",
    "# 1. Distance between members of its own group\n",
    "\n",
    "n_train = 500\n",
    "dist_hetero = np.ndarray(shape = (n_train, n_train))\n",
    "dist_homo = np.ndarray(shape = (n_train, n_train))\n",
    "\n",
    "for i in range(n_train):\n",
    "    for j in range(n_train):\n",
    "        if j <= i:\n",
    "            # Make dist with itself and repeating distances irrelevant\n",
    "            dist_hetero[i][j] = -1\n",
    "            dist_homo[i][j] = -1\n",
    "        elif train_y[i] == train_y[j]: #the points are within the same category\n",
    "            dist_hetero[i][j] = -1\n",
    "            dist_homo[i][j] = np.linalg.norm(pred_auto_train[i] - pred_auto_train[j])\n",
    "        else: #the points are in different categories\n",
    "            dist_hetero[i][j] = np.linalg.norm(pred_auto_train[i] - pred_auto_train[j])\n",
    "            dist_homo[i][j] = -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_hetero_flattened = np.reshape(dist_hetero, (1, -1))\n",
    "dist_homo_flattened = np.reshape(dist_homo, (1, -1))\n",
    "\n",
    "dist_hetero_done = dist_hetero_flattened[dist_hetero_flattened != -1]\n",
    "dist_homo_done = dist_homo_flattened[dist_homo_flattened != -1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Number of datapoints')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/jbang36/anaconda3/envs/jb_py35/lib/python3.5/site-packages/matplotlib/figure.py:2369: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  warnings.warn(\"This figure includes Axes that are not compatible \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# redraw histogram\n",
    "import matplotlib.pyplot as plt\n",
    "fig, axs = plt.subplots(1, 2, sharey=True, tight_layout=True)\n",
    "axs[0].hist(dist_hetero_done, bins=5000)\n",
    "axs[0].set_title(\"Heterogeneous groups\")\n",
    "axs[0].set_xlabel(\"Distance\")\n",
    "axs[0].set_ylabel(\"Number of datapoints\")\n",
    "axs[1].hist(dist_homo_done, bins = 5000)\n",
    "axs[1].set_title(\"Homogeneous groups\")\n",
    "axs[1].set_xlabel(\"Distance between points\")\n",
    "axs[1].set_ylabel(\"Number of datapoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

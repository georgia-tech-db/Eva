{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b18c8d8c",
   "metadata": {},
   "source": [
    "### Launch EVA DB\n",
    "Run the command `python eva.py` in the server where you want to deploy EVA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5b2a6f",
   "metadata": {},
   "source": [
    "### Establish Connection With Eva DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62e83a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "from eva.server.db_api import connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b78a43e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "connection = connect(host = '0.0.0.0', port = 5432) # hostname, port of the server where EVADB is running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bc99e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d64d3b6",
   "metadata": {},
   "source": [
    "### Upload the survellience video to analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "130b8561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@status: 0\n",
      "@batch: Batch Object:\n",
      "@dataframe:                                                    0\n",
      "0  Video successfully added at location: /root/.e...\n",
      "@batch_size: 1\n",
      "@identifier_column: None\n",
      "@query_time: 3.8355576260000817\n"
     ]
    }
   ],
   "source": [
    "cursor.execute('UPLOAD INFILE \"../data/ua_detrac/ua_detrac.mp4\" INTO MyTrafficVideo;')\n",
    "response = cursor.fetch_all()\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6450f505",
   "metadata": {},
   "source": [
    "### Visualize Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bef7026f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "654664f6deac4e4e97bd5c5bd7a1cabd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Video(value=b'\\x00\\x00\\x00 ftypisom\\x00\\x00\\x02\\x00isomiso2avc1mp41\\x00\\x00\\x00\\x08free...')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import Video\n",
    "Video.from_file(\"../data/ua_detrac/ua_detrac.mp4\", embed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09a40cb",
   "metadata": {},
   "source": [
    "### Optional - Register FasterRCNN (object detection) model into EVA \n",
    "\n",
    "#### Syntax\n",
    "  ```\n",
    "  CREATE UDF [ IF NOT EXISTS ] <name> \n",
    "  INPUT  ( [ <arg_name> <arg_data_type> ] [ , ... ] )\n",
    "  OUTPUT ( [ <result_name> <result_data_type> ] [ , ... ] )\n",
    "  TYPE  <udf_type_name>\n",
    "  IMPL  '<path_to_implementation>'\n",
    "  ```\n",
    "\n",
    "#### Required Parameters\n",
    "`<name>` - specifies the unique identifier for the UDF.\n",
    "\n",
    "`[ <arg_name> <arg_data_type> ] [ , ... ]` - specifies the name and data type of the udf input arguments. Name is kept for consistency (ignored by eva right now), arguments data type is required. `ANYDIM` means the shape is inferred at runtime.\n",
    "\n",
    "`[ <result_name> <result_data_type> ] [ , ... ]` - specifies the name and data type of the udf output arguments. \n",
    "Users can access a specific output of the UDF similar to access a column of a table. Eg. `<name>.<result_name>` \n",
    "\n",
    "`<udf_type_name>` - specifies the identifier for the type of the UDF. UDFs of the same type are assumed to be interchangeable. They should all have identical input and output arguments. For example, object classification can be one type. \n",
    "\n",
    "`<path_to_implementation>` - specifies the path to the implementation class for the UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e83e5a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@status: 0\n",
      "@batch: Batch Object:\n",
      "@dataframe:                                                    0\n",
      "0  UDF FastRCNNObjectDetector successfully added ...\n",
      "@batch_size: 1\n",
      "@identifier_column: None\n",
      "@query_time: 0.3601013950010383\n"
     ]
    }
   ],
   "source": [
    "cursor.execute(\"\"\"CREATE UDF IF NOT EXISTS FastRCNNObjectDetector\n",
    "      INPUT  (frame NDARRAY UINT8(3, ANYDIM, ANYDIM))\n",
    "      OUTPUT (labels NDARRAY STR(ANYDIM), bboxes NDARRAY FLOAT32(ANYDIM, 4),\n",
    "                scores NDARRAY FLOAT32(ANYDIM))\n",
    "      TYPE  Classification\n",
    "      IMPL  '/workspace/eva/eva/udfs/fastrcnn_object_detector.py';\n",
    "      \"\"\")\n",
    "response = cursor.fetch_all()\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbd789e",
   "metadata": {},
   "source": [
    "### Run Object detector on the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91bdcaca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@status: 0\n",
      "@batch: Batch Object:\n",
      "@dataframe:    mytrafficvideo.id                      fastrcnnobjectdetector.labels  \\\n",
      "0                  0  [person, car, car, car, car, car, car, car, ca...   \n",
      "1                  1  [person, car, car, car, car, car, car, car, ca...   \n",
      "2                  2  [person, car, car, car, car, car, car, car, ca...   \n",
      "3                  3  [person, car, car, car, car, car, car, car, ca...   \n",
      "4                  4  [person, car, car, car, car, car, car, car, ca...   \n",
      "5                  5  [person, car, car, car, car, car, car, car, ca...   \n",
      "6                  6  [person, car, car, car, car, car, car, car, ca...   \n",
      "7                  7  [person, car, car, car, car, car, car, car, ca...   \n",
      "8                  8  [person, car, car, car, car, car, car, car, ca...   \n",
      "9                  9  [person, car, car, car, car, car, car, car, ca...   \n",
      "\n",
      "                       fastrcnnobjectdetector.bboxes  \\\n",
      "0  [[636.24609375, 363.6267700195, 670.9285888672...   \n",
      "1  [[636.348815918, 364.4110412598, 671.456970214...   \n",
      "2  [[636.6950683594, 367.780670166, 671.499389648...   \n",
      "3  [[637.3386230469, 370.0677490234, 671.13787841...   \n",
      "4  [[637.3938598633, 371.9588928223, 671.40667724...   \n",
      "5  [[637.3751831055, 374.4489440918, 671.94543457...   \n",
      "6  [[637.5088500977, 376.1438903809, 672.65002441...   \n",
      "7  [[636.910949707, 379.3989257812, 672.609863281...   \n",
      "8  [[637.6723632812, 381.3916015625, 673.54711914...   \n",
      "9  [[637.6342163086, 384.8502502441, 673.79156494...   \n",
      "\n",
      "                       fastrcnnobjectdetector.scores  \n",
      "0  [0.9973133206, 0.9954667091, 0.9945367575, 0.9...  \n",
      "1  [0.9986808896, 0.9966157079000001, 0.994604766...  \n",
      "2  [0.9988935590000001, 0.9963032007, 0.994643449...  \n",
      "3  [0.9984732270000001, 0.9947209358, 0.993759810...  \n",
      "4  [0.9979975820000001, 0.9953624606, 0.994491815...  \n",
      "5  [0.9974440336, 0.9945591092, 0.994469404200000...  \n",
      "6  [0.9984986782, 0.9972353578, 0.995693922000000...  \n",
      "7  [0.9991289973, 0.9968909621, 0.995028317, 0.99...  \n",
      "8  [0.9985589385, 0.9978938699000001, 0.997424840...  \n",
      "9  [0.9979318380000001, 0.9957094193, 0.995102763...  \n",
      "@batch_size: 10\n",
      "@identifier_column: None\n",
      "@query_time: 22.110507969000537\n"
     ]
    }
   ],
   "source": [
    "cursor.execute(\"\"\"SELECT id, FastRCNNObjectDetector(data) FROM MyTrafficVideo WHERE id<10\"\"\")\n",
    "response = cursor.fetch_all()\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81ed233",
   "metadata": {},
   "source": [
    "### Visualize output of Object detector on the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecc977d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def annotate_video(detections, input_video_path, output_video_path):\n",
    "    color=(0,255,0)\n",
    "    thickness=3\n",
    "\n",
    "    vcap = cv2.VideoCapture(input_path)\n",
    "    width = int(vcap.get(3))\n",
    "    height = int(vcap.get(4))\n",
    "    fps = vcap.get(5)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MJPG') #codec\n",
    "    video=cv2.VideoWriter(output_path, fourcc, fps, (width,height))\n",
    "\n",
    "    frame_id = 0\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = vcap.read()  # ret = 1 if the video is captured; frame is the image\n",
    "\n",
    "    while ret:\n",
    "        df = detections\n",
    "        df = df[['fastrcnnobjectdetector.bboxes', 'fastrcnnobjectdetector.labels']][df['mytrafficvideo.id'] == frame_id]\n",
    "        if df.size:\n",
    "            for bboxes, labels in df.values:\n",
    "                for i in range(len(bboxes)):\n",
    "                    bbox = bboxes[i]\n",
    "                    label = labels[i]\n",
    "                    x1, y1, x2, y2 = bbox\n",
    "                    x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "                    img=cv2.rectangle(frame, (x1, y1), (x2, y2), color, thickness) # object bbox\n",
    "                    cv2.putText(img, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, thickness-1) # object label\n",
    "            video.write(img)\n",
    "\n",
    "        frame_id+=1\n",
    "        ret, frame = vcap.read()\n",
    "\n",
    "    video.release()\n",
    "    vcap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a2dee29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import Video\n",
    "input_path = '../data/ua_detrac/ua_detrac.mp4'\n",
    "output_path = 'video.avi'\n",
    "annotate_video(response.batch.frames, input_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6969f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('test_eva_db': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "1dbd882c97e8cc10d04c788d83c90a5bd7f07f60066c26f3fe8ea9a0af7ed11a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
